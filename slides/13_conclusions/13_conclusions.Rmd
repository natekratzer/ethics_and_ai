---
title: "Conclusions"
author: 
  - "Dr. Nate Kratzer"
date: "2021-07-23"
output:
  xaringan::moon_reader:
    css: xaringan-themer.css
    nature:
      slideNumberFormat: "%current%"
      highlightStyle: github
      highlightLines: true
      ratio: 16:9
      countIncrementalSlides: true
      titleSlideClass: ["bg_water", "inverse", "center", "middle"]
---

class: bg_water

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(
  fig.width=9, fig.height=3.5, fig.retina=3,
  out.width = "100%",
  cache = FALSE,
  echo = TRUE,
  message = FALSE, 
  warning = FALSE,
  fig.show = TRUE,
  hiline = TRUE
)
```

```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer)
style_duo_accent(
  primary_color = "#1381B0",
  secondary_color = "#1381B0",
  inverse_header_color = "#FFFFFF"
)
```

```{css, echo = F}
.bg_water {
  position: relative;
  z-index: 1;
}

.bg_water::before {    
      content: "";
      background-image: url('img/water.jpg');
      background-size: cover;
      position: absolute;
      top: 0px;
      right: 0px;
      bottom: 0px;
      left: 0px;
      opacity: 0.25;
      z-index: -1;
}
```

## Thinking about AI and Ethics

- Power
- Perspective
- Practice

---

class: bg_water 

## Power

- Power differentials are real
- The benefits of AI and the harms of AI are felt by different groups of people
  - Race, Gender, Class, Geography
- The work that goes into data collection for a model can over be rendered invisible

---

class: bg_water

## Perspective

- Analytics involves breaking down the big picture to look at the pieces
- A major risk is losing sight of the big picture altogether!
- Context matters
- Different people will see different things in data science problems. Privilege Hazard is the result of blindspots that people in privileged positions have. 
- There is no neutral data visualization or neutral algorithm. They are reflections of the people who make them.
- The lending problem: You cannot satisfy all reasonable mathematical definitions of 'fairness' at the same time.
- AI cannot replace human judgment. This means we still have a lot of difficult problems to solve. 

---

class: bg_water center middle

## Practice

---

class: bg_water center middle

Virtue Ethics

>A just society can't be achieved simply by maximizing utility or by securing freedom of choice. To achieve a just society, we have to reason together about the meaning of the good life, and to create a public culture hospitable to the disagreements that will inevitably arise

Michael Sandel, Justice p. 261

---

class: bg_water 

## A Checklist for Thoughtful Data Science

- Have we listed how this technology can be attacked or abused?
- Have we tested our training data to ensure it is fair and representative?
- Have we studied and understood possible sources of bias in our data?
- Does our team reflect diversity of opinions, backgrounds, and kinds of thought?
- What kind of user consent do we need to collect to use the data?
- Do we have a mechanism for gathering consent from users?
- Have we explained clearly what users are consenting to?
- Do we have a mechanism for redress if people are harmed by the results?
- Can we shut down this software in production if it is behaving badly?
- Have we tested for fairness with respect to different user groups?
- Have we tested for disparate error rates among different user groups?
- Do we test and monitor for model drift to ensure our software remains fair over time?
- Do we have a plan to protect and secure user data?

https://www.oreilly.com/radar/of-oaths-and-checklists/



